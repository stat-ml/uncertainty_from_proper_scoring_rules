{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fdd0aacc-2c95-453d-9bd8-d7f3abb0fee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "stty: 'standard input': Inappropriate ioctl for device\n"
     ]
    }
   ],
   "source": [
    "from source.source.postprocessing_utils import (\n",
    "    get_uncertainty_scores,\n",
    "    get_predicted_labels,\n",
    "    get_missclassification_dataframe,\n",
    "    get_ood_detection_dataframe,\n",
    "    get_raw_scores_dataframe,\n",
    ")\n",
    "\n",
    "from source.datasets.constants import DatasetName\n",
    "from source.losses.constants import LossName\n",
    "from source.models.constants import ModelName\n",
    "from source.metrics import (\n",
    "    ApproximationType,\n",
    "    GName,\n",
    "    RiskType,\n",
    ")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "pd.set_option(\"display.max_rows\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616c37e2-af1d-4198-aee4-4e69d426c12f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76806699-ee5f-4d66-8b7b-f5f43bf73379",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_score_dict = {\n",
    "    \"cross_entropy\": \"Logscore\",\n",
    "    \"brier_score\": \"Brier\",\n",
    "    \"spherical_score\": \"Spherical\",\n",
    "}\n",
    "\n",
    "training_dataset_names = [\n",
    "    \"cifar10\",\n",
    "    \"cifar100\",\n",
    "    \"noisy_cifar100\",\n",
    "    \"missed_class_cifar10\",\n",
    "    \"noisy_cifar10\",\n",
    "]\n",
    "temperature = 1.0\n",
    "model_ids = np.arange(20)\n",
    "\n",
    "list_extraction_datasets = [\n",
    "    \"cifar10\",\n",
    "    \"cifar100\",\n",
    "    \"svhn\",\n",
    "    \"blurred_cifar100\",\n",
    "    \"blurred_cifar10\",\n",
    "]\n",
    "list_ood_datasets = [el for el in list_extraction_datasets]\n",
    "\n",
    "loss_function_names = [el for el in LossName]\n",
    "\n",
    "full_dataframe = None\n",
    "full_ood_rocauc_dataframe = None\n",
    "full_mis_rocauc_dataframe = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a40f2985-866d-470b-80ca-011d717702ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4af5351b1dae4c39b0107b54afa9ff80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/108 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e57a1736be454667aa453d464435b95f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/108 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../../external_repos/pytorch_cifar10/checkpoints/vgg19/CrossEntropy/0/embeddings_cifar10.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 15\u001b[0m\n\u001b[1;32m     11\u001b[0m     training_dataset_name_aux \u001b[38;5;241m=\u001b[39m training_dataset_name\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m architecture \u001b[38;5;129;01min\u001b[39;00m architectures:\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;66;03m# try:\u001b[39;00m\n\u001b[1;32m     14\u001b[0m     uq_results, embeddings_per_dataset, targets_per_dataset \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m---> 15\u001b[0m         \u001b[43mget_uncertainty_scores\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m            \u001b[49m\u001b[43mloss_function_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_function_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtraining_dataset_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining_dataset_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m            \u001b[49m\u001b[43marchitecture\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43marchitecture\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlist_extraction_datasets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlist_extraction_datasets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m            \u001b[49m\u001b[43muse_cached\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m     )\n\u001b[1;32m     26\u001b[0m     df_ood \u001b[38;5;241m=\u001b[39m get_ood_detection_dataframe(\n\u001b[1;32m     27\u001b[0m         ind_dataset\u001b[38;5;241m=\u001b[39mtraining_dataset_name_aux,\n\u001b[1;32m     28\u001b[0m         uq_results\u001b[38;5;241m=\u001b[39muq_results,\n\u001b[1;32m     29\u001b[0m         list_ood_datasets\u001b[38;5;241m=\u001b[39mlist_ood_datasets,\n\u001b[1;32m     30\u001b[0m     )\n\u001b[1;32m     31\u001b[0m     df_ood[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marchitecture\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m architecture\n",
      "File \u001b[0;32m/home/nkotelevskii/github/uncertainty_from_proper_scoring_rules/psruq/source/source/postprocessing_utils.py:403\u001b[0m, in \u001b[0;36mget_uncertainty_scores\u001b[0;34m(loss_function_names, training_dataset_name, architecture, model_ids, list_extraction_datasets, temperature, use_cached)\u001b[0m\n\u001b[1;32m    401\u001b[0m uq_results[uq_name] \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    402\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m loss_function_name \u001b[38;5;129;01min\u001b[39;00m loss_function_names:\n\u001b[0;32m--> 403\u001b[0m     embeddings_per_dataset, targets_per_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mcollect_embeddings\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    404\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    405\u001b[0m \u001b[43m        \u001b[49m\u001b[43marchitecture\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43marchitecture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    406\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloss_function_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_function_name\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    407\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtraining_dataset_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining_dataset_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    408\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlist_extraction_datasets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlist_extraction_datasets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    409\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    412\u001b[0m     uq_results[uq_name][loss_function_name] \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    413\u001b[0m     embeddings_per_dataset_all[loss_function_name] \u001b[38;5;241m=\u001b[39m embeddings_per_dataset\n",
      "File \u001b[0;32m/home/nkotelevskii/github/uncertainty_from_proper_scoring_rules/psruq/source/source/evaluation_utils.py:181\u001b[0m, in \u001b[0;36mcollect_embeddings\u001b[0;34m(model_ids, architecture, loss_function_name, training_dataset_name, list_extraction_datasets, temperature)\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model_id \u001b[38;5;129;01min\u001b[39;00m model_ids:\n\u001b[1;32m    174\u001b[0m     path_to_model_folder \u001b[38;5;241m=\u001b[39m make_load_path(\n\u001b[1;32m    175\u001b[0m         architecture\u001b[38;5;241m=\u001b[39marchitecture,\n\u001b[1;32m    176\u001b[0m         loss_function_name\u001b[38;5;241m=\u001b[39mloss_function_name,\n\u001b[1;32m    177\u001b[0m         dataset_name\u001b[38;5;241m=\u001b[39mtraining_dataset_name,\n\u001b[1;32m    178\u001b[0m         model_id\u001b[38;5;241m=\u001b[39mmodel_id\n\u001b[1;32m    179\u001b[0m     )\n\u001b[0;32m--> 181\u001b[0m     loaded_dict \u001b[38;5;241m=\u001b[39m \u001b[43mload_dict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m        \u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpath_to_model_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43membeddings_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mextraction_dataset_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.pkl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[1;32m    185\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    188\u001b[0m     loaded_embeddings \u001b[38;5;241m=\u001b[39m loaded_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124membeddings\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m/\u001b[39m temperature\n\u001b[1;32m    189\u001b[0m     loaded_targets \u001b[38;5;241m=\u001b[39m loaded_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m/home/nkotelevskii/github/uncertainty_from_proper_scoring_rules/psruq/source/source/data_utils.py:167\u001b[0m, in \u001b[0;36mload_dict\u001b[0;34m(load_path)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_dict\u001b[39m(load_path: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mdict\u001b[39m:\n\u001b[1;32m    159\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"The function loads dict from a specific file\u001b[39;00m\n\u001b[1;32m    160\u001b[0m \n\u001b[1;32m    161\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;124;03m        dict: _description_\u001b[39;00m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 167\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(load_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m    168\u001b[0m         loaded_dict \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(file)\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loaded_dict\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../external_repos/pytorch_cifar10/checkpoints/vgg19/CrossEntropy/0/embeddings_cifar10.pkl'"
     ]
    }
   ],
   "source": [
    "for training_dataset_name in training_dataset_names:\n",
    "    if training_dataset_name not in [\n",
    "        \"missed_class_cifar10\",\n",
    "        \"noisy_cifar10\",\n",
    "        \"noisy_cifar100\",\n",
    "    ]:\n",
    "        architectures = [ModelName.RESNET18, ModelName.VGG19]\n",
    "        training_dataset_name_aux = training_dataset_name\n",
    "    else:\n",
    "        architectures = [\"resnet18\"]\n",
    "        training_dataset_name_aux = training_dataset_name.split(\"_\")[-1]\n",
    "    for architecture in architectures:\n",
    "        # try:\n",
    "        uq_results, embeddings_per_dataset, targets_per_dataset = (\n",
    "            get_uncertainty_scores(\n",
    "                loss_function_names=loss_function_names,\n",
    "                training_dataset_name=training_dataset_name,\n",
    "                architecture=architecture,\n",
    "                model_ids=model_ids,\n",
    "                list_extraction_datasets=list_extraction_datasets,\n",
    "                temperature=temperature,\n",
    "                use_cached=False,\n",
    "            )\n",
    "        )\n",
    "\n",
    "        df_ood = get_ood_detection_dataframe(\n",
    "            ind_dataset=training_dataset_name_aux,\n",
    "            uq_results=uq_results,\n",
    "            list_ood_datasets=list_ood_datasets,\n",
    "        )\n",
    "        df_ood[\"architecture\"] = architecture\n",
    "        df_ood[\"training_dataset\"] = training_dataset_name\n",
    "\n",
    "        max_ind = int(\n",
    "            targets_per_dataset[training_dataset_name_aux].shape[0] / len(model_ids)\n",
    "        )\n",
    "        true_labels = targets_per_dataset[training_dataset_name_aux][:max_ind]\n",
    "\n",
    "        pred_labels = get_predicted_labels(\n",
    "            embeddings_per_dataset=embeddings_per_dataset,\n",
    "            training_dataset_name=training_dataset_name_aux,\n",
    "        )\n",
    "\n",
    "        df_misclassification = get_missclassification_dataframe(\n",
    "            ind_dataset=training_dataset_name_aux,\n",
    "            uq_results=uq_results,\n",
    "            true_labels=true_labels,\n",
    "            pred_labels=pred_labels,\n",
    "        )\n",
    "        df_misclassification[\"architecture\"] = architecture\n",
    "        df_misclassification[\"training_dataset\"] = training_dataset_name\n",
    "\n",
    "        # except Exception as ex:\n",
    "        #     print(training_dataset_name, ex)\n",
    "        #     continue\n",
    "\n",
    "        scores_df_unravel = get_raw_scores_dataframe(uq_results=uq_results)\n",
    "        scores_df_unravel[\"architecture\"] = architecture\n",
    "        scores_df_unravel[\"training_dataset\"] = training_dataset_name\n",
    "\n",
    "        if full_dataframe is None:\n",
    "            full_dataframe = scores_df_unravel\n",
    "            full_ood_rocauc_dataframe = df_ood\n",
    "            full_mis_rocauc_dataframe = df_misclassification\n",
    "        else:\n",
    "            full_dataframe = pd.concat([full_dataframe, scores_df_unravel])\n",
    "            full_ood_rocauc_dataframe = pd.concat([full_ood_rocauc_dataframe, df_ood])\n",
    "            full_mis_rocauc_dataframe = pd.concat(\n",
    "                [full_mis_rocauc_dataframe, df_misclassification]\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708f67f2-e478-4a58-a4c2-6ef28947a5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern_baserule = r'(Logscore|Brier|Neglog|Maxprob|Spherical)'\n",
    "pattern_risk = r'(Total|Bayes|Excess|Reverse Bregman Information|Bregman Information|Expected Pairwise Bregman Information|MVBI|MV|BiasBI|Bias)'\n",
    "\n",
    "full_ood_rocauc_dataframe['base_rule'] = full_ood_rocauc_dataframe['UQMetric'].str.extract(pattern_baserule)\n",
    "full_ood_rocauc_dataframe['RiskType'] = full_ood_rocauc_dataframe['UQMetric'].str.extract(pattern_risk)\n",
    "full_ood_rocauc_dataframe['LossFunction'] = full_ood_rocauc_dataframe['LossFunction'].replace(base_score_dict)\n",
    "\n",
    "full_mis_rocauc_dataframe['base_rule'] = full_mis_rocauc_dataframe['UQMetric'].str.extract(pattern_baserule)\n",
    "full_mis_rocauc_dataframe['RiskType'] = full_mis_rocauc_dataframe['UQMetric'].str.extract(pattern_risk)\n",
    "full_mis_rocauc_dataframe['LossFunction'] = full_mis_rocauc_dataframe['LossFunction'].replace(base_score_dict)\n",
    "\n",
    "full_dataframe['base_rule'] = full_dataframe['UQMetric'].str.extract(pattern_baserule)\n",
    "full_dataframe['RiskType'] = full_dataframe['UQMetric'].str.extract(pattern_risk)\n",
    "full_dataframe['LossFunction'] = full_dataframe['LossFunction'].replace(base_score_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48d17a4-88cc-477b-a6fd-c315de7052bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataframe.to_csv('./tables/full_dataframe.csv')\n",
    "full_ood_rocauc_dataframe.to_csv('./tables/full_ood_rocauc.csv')\n",
    "full_mis_rocauc_dataframe.to_csv('./tables/full_mis_rocauc.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
